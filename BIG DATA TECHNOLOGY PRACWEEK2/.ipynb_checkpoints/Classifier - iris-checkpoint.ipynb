{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import the datasets\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now be working on the dataset iris, which is already packaged in Sklearn\n",
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of course here an EDA is required to better understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the dataset into training and testing\n",
    "from sklearn import model_selection\n",
    "# in this specific dataset, the target (or the true values) is accessed using data.target\n",
    "# however, in another dataset, it might be in a feature within the dataset \n",
    "# and we might need to split the dataset and separate the target from the other values\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(dataset.data, dataset.target, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# then we create an empty instance of the model\n",
    "lm = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now fit the model o the training set\n",
    "lm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the model is trained, now we can make some predictions on the test set\n",
    "predicted = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally we can present the confusion matrix and other performance measures\n",
    "confusionMatrix = metrics.confusion_matrix(Y_test, predicted)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "# Print Confusion Matrix with seaborn\n",
    "ax = sns.heatmap(confusionMatrix, annot=True, fmt='.0f')\n",
    "plt.title('Confusion Matrix', fontsize = 20) # title with fontsize 20\n",
    "plt.xlabel('Predicted values', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True values', fontsize = 15) # y-axis label with fontsize 15\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix with seaborn\n",
    "import numpy as np\n",
    "ax = sns.heatmap(confusionMatrix / np.sum(confusionMatrix), annot=True, fmt='.1%', cmap='Blues')\n",
    "plt.title('Confusion Matrix', fontsize = 20) # title with fontsize 20\n",
    "plt.xlabel('Predicted values', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True values', fontsize = 15) # y-axis label with fontsize 15\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Classification Report\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(dataset.data, dataset.target, test_size = 0.30)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(dataset.data, dataset.target, test_size = 0.30)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(dataset.data, dataset.target, test_size = 0.30)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
